import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import japanize_matplotlib
from datetime import datetime
from typing import List, Tuple
import numpy as np
import os
import re
from matplotlib.patches import Patch

# ç°è‰²ã‹ã³ç—…ãƒªã‚¹ã‚¯ãƒã‚§ãƒƒã‚¯é–¢æ•°
def check_gray_mold_risk(temp_humidity_data: List[Tuple[float, float]], timestamps) -> Tuple[str, int, str]:
    """
    æœ€æ–°ã®10æ—¥é–“(240æ™‚é–“)ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã‚’ç®—å‡ºã™ã‚‹é–¢æ•°
    """
    # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã‚½ãƒ¼ãƒˆ
    data_sorted = sorted(zip(temp_humidity_data, timestamps), key=lambda x: x[1])
    
    if not data_sorted:
        return "ãƒ‡ãƒ¼ã‚¿ãªã—", 0, "gray"
    
    # æœ€æ–°ã®æ—¥æ™‚
    latest_timestamp = max(ts for _, ts in data_sorted)
    
    # 10æ—¥å‰ã®æ—¥æ™‚
    window_start = latest_timestamp - pd.Timedelta(hours=240)
    
    # éå»10æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    recent_window = [(temp, humidity) for (temp, humidity), ts in data_sorted 
                    if window_start <= ts <= latest_timestamp]
    
    # ãƒªã‚¹ã‚¯æ™‚é–“ã‚’è¨ˆç®—
    risk_hours = sum(
        1 for temp, humidity in recent_window
        if 15 <= float(temp) <= 25 and float(humidity) >= 94
    )
    
    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã¨ã‚«ãƒ©ãƒ¼ã‚’æ±ºå®š
    if risk_hours == 0:
        return "æ¥µä½", risk_hours, "blue"
    elif 0 < risk_hours <= 10:
        return "ä½", risk_hours, "blue"
    elif 10 < risk_hours <= 20:
        return "ä¸­", risk_hours, "green"
    elif 20 < risk_hours <= 39:
        return "é«˜", risk_hours, "orange"
    else:
        return "æ¥µé«˜", risk_hours, "red"

# CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ã¨ç›¸å¯¾æ¹¿åº¦ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
def read_temperature_and_humidity_data(file_obj, device_type=None, days_to_keep=30):
    """
    æ§˜ã€…ãªå½¢å¼ã®ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ¸©åº¦ã¨æ¹¿åº¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
    
    Parameters:
    ----------
    file_obj : UploadedFile ã¾ãŸã¯ str
        Streamlitã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    device_type : str, optional
        ãƒ‡ãƒã‚¤ã‚¹ã‚¿ã‚¤ãƒ— ('HZ', 'PF', 'PF2', 'SB', 'OT', 'HN', None)
    days_to_keep : int, optional
        ä¿æŒã™ã‚‹æ—¥æ•°ï¼ˆæœ€æ–°ã®Næ—¥åˆ†ï¼‰ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯30æ—¥ã€‚
    """
    
    # ãƒ¡ã‚¤ãƒ³å‡¦ç†é–‹å§‹
    temp_path = None
    try:
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        import tempfile
        if hasattr(file_obj, 'read'):  # UploadedFileã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
            with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
                tmp_file.write(file_obj.getbuffer())
                temp_path = tmp_file.name
        else:  # æ–‡å­—åˆ—ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼‰ã®å ´åˆ
            temp_path = file_obj
        
        # ãƒ‡ãƒã‚¤ã‚¹è¨­å®šã®å®šç¾©ï¼ˆè¾æ›¸ã‚’æ´»ç”¨ï¼‰
        # å„ãƒ‡ãƒã‚¤ã‚¹ã‚¿ã‚¤ãƒ—ã«å¯¾å¿œã™ã‚‹åˆ—åã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é›†ç´„
        device_configs = {
            'HZ': {
                'temp_cols': ['æ¸©åº¦'],
                'humid_cols': ['æ¹¿åº¦'],
                'timestamp_cols': ['æ—¥ä»˜'],
                'encoding': 'shift-jis'
            },
            'PF': {
                'temp_cols': ['æ°—æ¸©'],
                'humid_cols': ['ç›¸å¯¾æ¹¿åº¦'],
                'timestamp_cols': ['å¹´æœˆæ—¥'],
                'encoding': 'shift-jis'
            },
            'PF2': {
                'temp_cols': ['PF æ¸¬å®š æ°—æ¸©'],
                'humid_cols': ['æ¹¿åº¦'],
                'timestamp_cols': ['datetime'],
                'encoding': 'shift-jis',
                'date_time_cols': {'date_col': 'æ—¥ä»˜', 'time_col': 'æ™‚åˆ»'}
            },
            'SB': {
                # SwitchBotç³»ã®ã™ã¹ã¦ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’çµ±åˆï¼ˆæ­£å¸¸ã€ã‚¿ã‚¤ãƒã€æ–‡å­—åŒ–ã‘å«ã‚€ï¼‰
                'temp_cols': [
                    'Temperature_Celsius(Â°C)', 'Temperature_Celsius(â„ƒ)', 'Temperature_Celsius(ï¾‚ï½°C)',
                    'Temperature_Celsius', 'Temperatre_Celsius(â„E', 'Temperatre_Celsius', 'Temperatre'
                ],
                'humid_cols': ['Relative_Humidity(%)', 'Relativ_Humidity(%)', 'Relativ_Humidity'],
                'timestamp_cols': ['Timestamp', 'Timamp', 'Date'],
                'encoding': 'utf-8'
            },
            'OT': {
                'temp_cols': ['å®¤æ¸©'],
                'humid_cols': ['æ¹¿åº¦'],
                'timestamp_cols': ['æ—¥ä»˜'],
                'encoding': 'shift-jis'
            },
            'HN': {
                'temp_cols': ['æ¸©åº¦(â„ƒ)'],
                'humid_cols': ['ç›¸å¯¾æ¹¿åº¦(ï¼…)'],
                'timestamp_cols': ['æ—¥æ™‚'],
                'encoding': 'utf-8-sig'
            },
            'KN': {
                # æ›æ°—ãƒŠãƒ“ï¼šè¤‡æ•°ã‚»ãƒ³ã‚µã®å¹³å‡å€¤ã‚’ä½¿ç”¨
                'temp_cols': ['æ¸©åº¦ã‚»ãƒ³ã‚µï¼‘(â„ƒ)', 'æ¸©åº¦ã‚»ãƒ³ã‚µï¼’(â„ƒ)', 'æ¸©åº¦ã‚»ãƒ³ã‚µï¼“(â„ƒ)', 'æ¸©åº¦ã‚»ãƒ³ã‚µï¼”(â„ƒ)'],
                'humid_cols': ['æ¹¿åº¦ï¼‘(%)', 'æ¹¿åº¦ï¼’(%)'],
                'timestamp_cols': ['æ—¥æ™‚'],
                'encoding': 'utf-8-sig',
                'use_average': True  # è¤‡æ•°ã‚»ãƒ³ã‚µã®å¹³å‡å€¤ã‚’ä½¿ç”¨
            }
        }
        
        # ãƒ‡ãƒã‚¤ã‚¹ã‚¿ã‚¤ãƒ—ã®è‡ªå‹•æ¤œå‡ºã‚’è©¦ã¿ã‚‹ï¼ˆãƒ‡ãƒã‚¤ã‚¹ã‚¿ã‚¤ãƒ—ãŒæœªæŒ‡å®šã®å ´åˆï¼‰
        if device_type is None:

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ç¢ºèª
            df, encoding = try_multiple_encodings(temp_path)
            if df is not None:
                cols = df.columns.tolist()

                # ç‰¹æ®Šãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡ºï¼ˆå„ªå…ˆé †ä½é †ï¼‰
                # PF2å½¢å¼ã®æ¤œå‡ºï¼ˆPF æ¸¬å®š æ°—æ¸© ã¨ æ—¥ä»˜+æ™‚åˆ»ãŒåˆ¥ã‚«ãƒ©ãƒ ï¼‰
                if any('PF æ¸¬å®š' in col for col in cols) or ('æ—¥ä»˜' in cols and 'æ™‚åˆ»' in cols and 'æ¹¿åº¦' in cols):
                    device_type = 'PF2'
                # KNå½¢å¼ã®æ¤œå‡ºï¼ˆæ¸©åº¦ã‚»ãƒ³ã‚µï¼‘ç­‰ã®å…¨è§’æ•°å­—ã‚’å«ã‚€ï¼‰
                elif any('æ¸©åº¦ã‚»ãƒ³ã‚µï¼‘' in col or 'æ¸©åº¦ã‚»ãƒ³ã‚µï¼’' in col for col in cols):
                    device_type = 'KN'
                # SBå½¢å¼ã®æ¤œå‡ºï¼ˆSwitchBotç³»ã€ã‚¿ã‚¤ãƒå«ã‚€ï¼‰
                elif any('Timestamp' in col or 'Timamp' in col or 'Temperature' in col or 'Temperatre' in col for col in cols):
                    device_type = 'SB'
                else:
                    # å„ãƒ‡ãƒã‚¤ã‚¹ã‚¿ã‚¤ãƒ—ã®ç‰¹å¾´ã¨ç…§åˆ
                    for dev, config in device_configs.items():
                        # æ¸©åº¦åˆ—ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                        for col_name in config['temp_cols']:
                            if col_name in cols:
                                device_type = dev
                                break
                        if device_type:
                            break

                # ãƒ•ã‚¡ã‚¸ãƒ¼ãƒãƒƒãƒãƒ³ã‚°ã§ã®æ¤œå‡ºï¼ˆæœ€çµ‚æ‰‹æ®µï¼‰
                if device_type is None:
                    for dev, config in device_configs.items():
                        matched = find_column_fuzzy(cols, config['temp_cols'])
                        if matched:
                            device_type = dev
                            break

            # è‡ªå‹•æ¤œå‡ºã§ããªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã¦SBã‚’ä½¿ç”¨
            if device_type is None:
                device_type = 'SB'
        
        # è¨­å®šã‚’å–å¾—
        config = device_configs.get(device_type, device_configs['SB'])

        # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        df, _ = try_multiple_encodings(temp_path)
        if df is None:
            st.error("ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return None, None, None
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—åˆ—ã®ç‰¹å®šã¨å‡¦ç†ï¼ˆãƒ‡ãƒã‚¤ã‚¹ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå‡¦ç†ï¼‰
        timestamp_found = False
        
        # PF2å½¢å¼ã®ç‰¹åˆ¥å‡¦ç†ï¼ˆæ—¥ä»˜ã¨æ™‚åˆ»ãŒåˆ¥ã€…ã®åˆ—ï¼‰
        if device_type == 'PF2' and 'æ—¥ä»˜' in df.columns and 'æ™‚åˆ»' in df.columns:
     
            # æ™‚åˆ»åˆ—ã‹ã‚‰ã‚¢ã‚¹ã‚¿ãƒªã‚¹ã‚¯ãªã©ã‚’å‰Šé™¤ã—ã¦çµåˆ
            date_col = config.get('date_time_cols', {}).get('date_col', 'æ—¥ä»˜')
            time_col = config.get('date_time_cols', {}).get('time_col', 'æ™‚åˆ»')
            
            df['datetime'] = combine_date_time(df, date_col, time_col)
            
            # NaTå€¤ã‚’ãƒã‚§ãƒƒã‚¯
            nat_count = df['datetime'].isna().sum()
            if nat_count > 0:
                df = df.dropna(subset=['datetime'])
            
            df = df.set_index('datetime')
            timestamp_found = True
            
        if device_type == 'SB':
            try:
                # SwitchBotãƒ•ã‚¡ã‚¤ãƒ«ã¯UTF-8ã§å¼·åˆ¶çš„ã«èª­ã¿ç›´ã—
                df = pd.read_csv(temp_path, encoding='utf-8')
            except Exception as e:
                st.warning(f"UTF-8ã§ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        
        # ä¸€èˆ¬çš„ãªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—åˆ—ã®å‡¦ç†
        if not timestamp_found:
            for ts_col in config['timestamp_cols']:
                if ts_col in df.columns:
                    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’datetimeå‹ã«å¤‰æ›ï¼ˆè¤‡æ•°ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è©¦è¡Œï¼‰
                    original_count = len(df)

                    # æ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆæ•°å€¤ã‚„ä»–ã®å‹ã®å ´åˆã«å¯¾å¿œï¼‰
                    ts_series = df[ts_col].astype(str).str.strip()

                    # ã¾ãšè‡ªå‹•è§£æã‚’è©¦ã¿ã‚‹
                    df['datetime'] = pd.to_datetime(ts_series, errors='coerce')

                    # å¤±æ•—ã—ãŸå ´åˆã€æ˜ç¤ºçš„ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è©¦ã™
                    nat_count = df['datetime'].isna().sum()
                    if nat_count == original_count:
                        # å…¨è¡Œå¤±æ•— -> ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ˜ç¤ºçš„ã«æŒ‡å®šã—ã¦å†è©¦è¡Œ
                        # æ§˜ã€…ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ã‚«ãƒãƒ¼ï¼ˆã‚¼ãƒ­åŸ‹ã‚ãªã—ã‚‚å«ã‚€ï¼‰
                        datetime_formats = [
                            '%Y/%m/%d %H:%M:%S',  # 2024/09/26 15:35:00
                            '%Y-%m-%d %H:%M:%S',  # 2024-09-26 15:35:00
                            '%Y/%m/%d %H:%M',     # 2024/09/26 15:35
                            '%Y-%m-%d %H:%M',     # 2024-09-26 15:35
                        ]
                        for fmt in datetime_formats:
                            try:
                                df['datetime'] = pd.to_datetime(ts_series, format=fmt, errors='coerce')
                                nat_count = df['datetime'].isna().sum()
                                if nat_count < original_count:
                                    break
                            except Exception:
                                continue

                        # ã¾ã å…¨è¡Œå¤±æ•—ã®å ´åˆã€æŸ”è»Ÿãªè§£æã‚’è©¦ã™
                        if nat_count == original_count:
                            try:
                                # infer_datetime_format=Trueã¯å»ƒæ­¢ã•ã‚ŒãŸãŸã‚ã€format='mixed'ã‚’ä½¿ç”¨
                                df['datetime'] = pd.to_datetime(ts_series, format='mixed', dayfirst=False, errors='coerce')
                            except Exception:
                                pass

                    # NaTå€¤ã‚’ãƒã‚§ãƒƒã‚¯
                    nat_count = df['datetime'].isna().sum()
                    if nat_count > 0:
                        df = df.dropna(subset=['datetime'])
                    df = df.set_index('datetime')
                    timestamp_found = True
                    break
        
        if not timestamp_found:
            # æ—¥ä»˜ã¨æ™‚åˆ»ãŒåˆ¥ã€…ã®åˆ—ã®å ´åˆï¼ˆä¸€èˆ¬çš„ãªã‚±ãƒ¼ã‚¹ï¼‰
            if 'æ—¥ä»˜' in df.columns and 'æ™‚åˆ»' in df.columns:
                df['datetime'] = combine_date_time(df, 'æ—¥ä»˜', 'æ™‚åˆ»')
                
                # NaTå€¤ã‚’ãƒã‚§ãƒƒã‚¯
                nat_count = df['datetime'].isna().sum()
                if nat_count > 0:
                    df = df.dropna(subset=['datetime'])
                
                df = df.set_index('datetime')
                timestamp_found = True
        
        if not timestamp_found:
            st.error("ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None, None, None
        
        if timestamp_found:
            if len(df) > 0:  # ç©ºã®DataFrameã§ãªã„ã“ã¨ã‚’ç¢ºèª
                # æœ€æ–°ã®æ—¥ä»˜ã‚’ç‰¹å®š
                latest_date = df.index.max()
                # æœŸé–“ã‚’è¨ˆç®—
                cutoff_date = latest_date - pd.Timedelta(days=days_to_keep)
                # æœŸé–“å†…ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ä¿æŒ
                df_filtered = df[df.index >= cutoff_date]

                # ãƒ•ã‚£ãƒ«ã‚¿å¾Œã«ãƒ‡ãƒ¼ã‚¿ãŒæ®‹ã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
                if not df_filtered.empty:
                    # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ›´æ–°
                    df = df_filtered
                else:
                    st.warning(f"æœ€æ–°ã®{days_to_keep}æ—¥é–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã—ã¾ã™ã€‚")
            
                
        # æ¸©åº¦ã¨æ¹¿åº¦ã®åˆ—ã‚’ç‰¹å®š
        temp_col = None
        humid_col = None

        # KNå½¢å¼ã®å ´åˆï¼šè¤‡æ•°ã‚»ãƒ³ã‚µã®å¹³å‡å€¤ã‚’ä½¿ç”¨
        if config.get('use_average', False):
            # æ¸©åº¦ã‚»ãƒ³ã‚µåˆ—ã‚’æ¤œç´¢
            temp_sensor_cols = []
            for col in config['temp_cols']:
                if col in df.columns:
                    temp_sensor_cols.append(col)
            # æ¹¿åº¦ã‚»ãƒ³ã‚µåˆ—ã‚’æ¤œç´¢
            humid_sensor_cols = []
            for col in config['humid_cols']:
                if col in df.columns:
                    humid_sensor_cols.append(col)

            if temp_sensor_cols and humid_sensor_cols:
                # æ•°å€¤å‹ã«å¤‰æ›
                df = convert_to_numeric(df, temp_sensor_cols + humid_sensor_cols)

                # å…¨ã¦NaNã®ã‚»ãƒ³ã‚µã®ã¿ã‚’é™¤å¤–ï¼ˆ0å€¤ã¯æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æ‰±ã†ï¼‰
                valid_temp_cols = [col for col in temp_sensor_cols if df[col].notna().any()]
                valid_humid_cols = [col for col in humid_sensor_cols if df[col].notna().any()]

                # é™¤å¤–ã•ã‚ŒãŸã‚»ãƒ³ã‚µãŒã‚ã‚‹å ´åˆã¯è­¦å‘Šã‚’è¡¨ç¤º
                excluded_temp = [col for col in temp_sensor_cols if col not in valid_temp_cols]
                excluded_humid = [col for col in humid_sensor_cols if col not in valid_humid_cols]
                if excluded_temp or excluded_humid:
                    excluded_msgs = [f"  - {col}: å…¨ã¦NaN" for col in excluded_temp + excluded_humid]
                    st.warning("ä»¥ä¸‹ã®ã‚»ãƒ³ã‚µã¯ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚é™¤å¤–ã•ã‚Œã¾ã—ãŸ:\n" + "\n".join(excluded_msgs))

                # æœ‰åŠ¹ãªã‚»ãƒ³ã‚µãŒã‚ã‚‹ã‹ç¢ºèª
                if not valid_temp_cols:
                    st.error("æœ‰åŠ¹ãªæ¸©åº¦ã‚»ãƒ³ã‚µãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆå…¨ã¦ã®ã‚»ãƒ³ã‚µãŒNaNã§ã™ï¼‰")
                    return None, None, None
                if not valid_humid_cols:
                    st.error("æœ‰åŠ¹ãªæ¹¿åº¦ã‚»ãƒ³ã‚µãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆå…¨ã¦ã®ã‚»ãƒ³ã‚µãŒNaNã§ã™ï¼‰")
                    return None, None, None

                # å¹³å‡å€¤ã‚’è¨ˆç®—ï¼ˆNaNå€¤ã¯ã‚¹ã‚­ãƒƒãƒ—ã€0å€¤ã¯æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦å«ã‚€ï¼‰
                df['_temp_avg'] = df[valid_temp_cols].mean(axis=1, skipna=True)
                df['_humid_avg'] = df[valid_humid_cols].mean(axis=1, skipna=True)
                temp_col = '_temp_avg'
                humid_col = '_humid_avg'
            else:
                st.error(f"ã‚»ãƒ³ã‚µåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½ãªåˆ—: {df.columns.tolist()}")
                return None, None, None
        else:
            # é€šå¸¸ã®ãƒ‡ãƒã‚¤ã‚¹ï¼šå®Œå…¨ä¸€è‡´ã‚’å…ˆã«è©¦ã™
            for col in config['temp_cols']:
                if col in df.columns:
                    temp_col = col
                    break

            for col in config['humid_cols']:
                if col in df.columns:
                    humid_col = col
                    break

            # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒ•ã‚¡ã‚¸ãƒ¼ãƒãƒƒãƒãƒ³ã‚°
            if temp_col is None:
                temp_col = find_column_fuzzy(df.columns.tolist(), config['temp_cols'])

            if humid_col is None:
                humid_col = find_column_fuzzy(df.columns.tolist(), config['humid_cols'])

            if temp_col is None or humid_col is None:
                st.error(f"å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¤œç´¢ã—ãŸåˆ—: {config['temp_cols']}, {config['humid_cols']}")
                st.error(f"åˆ©ç”¨å¯èƒ½ãªåˆ—: {df.columns.tolist()[:20]}...")  # æœ€åˆã®20åˆ—ã®ã¿è¡¨ç¤º
                return None, None, None

            # æ•°å€¤å‹ã«å¤‰æ›
            df = convert_to_numeric(df, [temp_col, humid_col])
        
        # NaNå€¤ã‚’å«ã‚€è¡Œã‚’é™¤å¤–
        df = df.dropna(subset=[temp_col, humid_col])

        # 1æ™‚é–“é–“éš”ã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        df = resample_to_hourly(df)

        # ãƒ‡ãƒ¼ã‚¿ç¢ºèª
        if temp_col not in df.columns or humid_col not in df.columns:
            st.error("ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            return None, None, None

        result_temp = df[temp_col].tolist()
        result_humid = df[humid_col].tolist()

        # çµæœã‚’è¿”ã™
        return result_temp, result_humid, df.index
    
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        import traceback
        st.text(traceback.format_exc())
        return None, None, None
    
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºå®Ÿã«å‰Šé™¤
        if temp_path and hasattr(file_obj, 'read'):
            try:
                import os
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
            except Exception as e:
                st.warning(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {str(e)}")

def try_multiple_encodings(file_path):
    """è¤‡æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦ã—ã¦CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°ï¼ˆBOMæ¤œå‡ºå¯¾å¿œï¼‰"""

    def read_with_encoding(file_path, encoding):
        """æŒ‡å®šã•ã‚ŒãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§CSVã‚’èª­ã¿è¾¼ã¿ã€æœ«å°¾ã®ç©ºã‚«ãƒ©ãƒ ã‚’å‰Šé™¤"""
        # ã¾ãšãƒ˜ãƒƒãƒ€ãƒ¼ã®åˆ—æ•°ã‚’å–å¾—
        with open(file_path, 'r', encoding=encoding) as f:
            header = f.readline()
        header_cols = len(header.strip().split(','))

        # ãƒ˜ãƒƒãƒ€ãƒ¼åˆ—æ•°ã«åˆã‚ã›ã¦ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ï¼ˆä½™åˆ†ãªåˆ—ã¯ç„¡è¦–ï¼‰
        df = pd.read_csv(file_path, encoding=encoding, usecols=range(header_cols))
        return df

    # BOMæ¤œå‡º
    try:
        with open(file_path, 'rb') as f:
            raw = f.read(4)

        # UTF-8 BOMã®æ¤œå‡º
        if raw.startswith(b'\xef\xbb\xbf'):
            try:
                df = read_with_encoding(file_path, 'utf-8-sig')
                return df, 'utf-8-sig'
            except Exception:
                pass
    except Exception:
        pass

    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å„ªå…ˆé †ä½ï¼ˆBOMãªã—ã®å ´åˆï¼‰
    encodings = ['utf-8', 'shift-jis', 'cp932', 'utf-8-sig']

    for encoding in encodings:
        try:
            df = read_with_encoding(file_path, encoding)
            return df, encoding
        except Exception:
            continue

    return None, None

def find_column_fuzzy(columns, patterns, threshold=0.6):
    """
    ãƒ•ã‚¡ã‚¸ãƒ¼ãƒãƒƒãƒãƒ³ã‚°ã§åˆ—åã‚’æ¤œç´¢ã™ã‚‹é–¢æ•°

    Parameters:
    ----------
    columns : list
        ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®åˆ—åãƒªã‚¹ãƒˆ
    patterns : list
        æ¤œç´¢ã™ã‚‹åˆ—åãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ–‡å­—åˆ—ã¾ãŸã¯æ­£è¦è¡¨ç¾ï¼‰
    threshold : float
        é¡ä¼¼åº¦ã®é–¾å€¤ï¼ˆ0-1ï¼‰

    Returns:
    -------
    str or None
        ãƒãƒƒãƒã—ãŸåˆ—åã€è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯None
    """
    from difflib import SequenceMatcher

    # ã¾ãšå®Œå…¨ä¸€è‡´ã‚’è©¦ã¿ã‚‹
    for pattern in patterns:
        if pattern in columns:
            return pattern

    # éƒ¨åˆ†ä¸€è‡´ã‚’è©¦ã¿ã‚‹ï¼ˆåˆ—åãŒãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å«ã‚€ï¼‰
    for pattern in patterns:
        for col in columns:
            if pattern.lower() in col.lower():
                return col

    # æ­£è¦è¡¨ç¾ãƒãƒƒãƒã‚’è©¦ã¿ã‚‹
    for pattern in patterns:
        for col in columns:
            try:
                if re.search(pattern, col, re.IGNORECASE):
                    return col
            except re.error:
                continue

    # ãƒ•ã‚¡ã‚¸ãƒ¼ãƒãƒƒãƒãƒ³ã‚°ï¼ˆé¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹ï¼‰
    for pattern in patterns:
        best_match = None
        best_ratio = 0
        for col in columns:
            # åˆ—åã‚’æ­£è¦åŒ–ã—ã¦æ¯”è¼ƒ
            ratio = SequenceMatcher(None, pattern.lower(), col.lower()).ratio()
            if ratio > best_ratio and ratio >= threshold:
                best_ratio = ratio
                best_match = col
        if best_match:
            return best_match

    return None

def combine_date_time(df, date_col='æ—¥ä»˜', time_col='æ™‚åˆ»'):
    """æ—¥ä»˜åˆ—ã¨æ™‚åˆ»åˆ—ã‚’çµåˆã—ã¦datetimeå‹ã®åˆ—ã‚’ä½œæˆã™ã‚‹é–¢æ•°"""
    try:
        # æ™‚åˆ»åˆ—ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆ*ã‚’å‰Šé™¤ï¼‰
        if time_col in df.columns:
            df[time_col] = df[time_col].astype(str).str.replace('*', '', regex=False)
            df[time_col] = df[time_col].str.strip()

        # è¡Œã”ã¨ã«æ—¥æ™‚ã‚’å¤‰æ›
        dates = []
        for _, row in df.iterrows():
            try:
                date_str = str(row[date_col]).strip()
                time_str = str(row[time_col]).strip()

                # æ™‚åˆ»ãŒæ•°å­—ã ã‘ã®å ´åˆã¯ ":00" ã‚’è¿½åŠ 
                if time_str.isdigit() and len(time_str) <= 2:
                    time_str = f"{time_str}:00"

                # æ—¥ä»˜ã¨æ™‚åˆ»ã‚’çµåˆ
                date_time_str = f"{date_str} {time_str}"

                # datetimeã«å¤‰æ›
                date_time = pd.to_datetime(date_time_str, errors='coerce')
                dates.append(date_time)

            except Exception:
                dates.append(pd.NaT)  # å¤‰æ›ã§ããªã„å ´åˆã¯NaNå€¤ã‚’è¿½åŠ 

        # æ–°ã—ã„æ—¥æ™‚åˆ—ã‚’ä½œæˆ
        return pd.Series(dates)
        
    except Exception as e:
        st.error(f"æ—¥ä»˜ã¨æ™‚åˆ»ã®çµåˆã«å¤±æ•—: {str(e)}")
        import traceback
        st.text(traceback.format_exc())
        return pd.Series([pd.NaT] * len(df))

def convert_to_numeric(df, columns):
    """æŒ‡å®šã•ã‚ŒãŸåˆ—ã‚’æ•°å€¤å‹ã«å¤‰æ›ã™ã‚‹é–¢æ•°"""
    for col in columns:
        try:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        except Exception as e:
            st.error(f"{col}ã®æ•°å€¤å¤‰æ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    return df

def resample_to_hourly(df):
    """ãƒ‡ãƒ¼ã‚¿ã‚’1æ™‚é–“é–“éš”ã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹é–¢æ•°"""
    try:
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒdatetimeã‹ãƒã‚§ãƒƒã‚¯
        if not isinstance(df.index, pd.DatetimeIndex):
            raise ValueError("æ—¥æ™‚ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ")
        # éæ•°å€¤åˆ—ã‚’é™¤å¤–
        numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
        if not numeric_cols:
            return df
        # æ•°å€¤åˆ—ã®ã¿ã‚’ä½¿ç”¨
        numeric_df = df[numeric_cols].copy()
        # 1æ™‚é–“é–“éš”ã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        numeric_df.index = numeric_df.index.floor('h')
        # ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã¨ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        df_hourly = numeric_df.groupby(numeric_df.index).mean()
        # æ¬ æå€¤ã®è£œé–“ (æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«é©ã—ãŸ method='time' ã‚’ä½¿ç”¨)
        df_resampled = df_hourly.resample('1h').interpolate(method='time')
        return df_resampled
    except Exception:
        return df

# æ™‚ç³»åˆ—ãƒªã‚¹ã‚¯è¨ˆç®—é–¢æ•°
def calculate_time_series_risk(temp_humidity_data, timestamps, days_to_show=30):
    """
    éå»Xæ—¥é–“ã®å„æ—¥ã«ãŠã‘ã‚‹ãƒªã‚¹ã‚¯ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
    å„æ—¥ä»˜ã‹ã‚‰é¡ã£ã¦10æ—¥é–“(240æ™‚é–“)ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ãƒªã‚¹ã‚¯åˆ¤å®š
    """
    # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã‚½ãƒ¼ãƒˆ
    data_sorted = sorted(zip(temp_humidity_data, timestamps), key=lambda x: x[1])
    
    # å„æ—¥ã®ãƒªã‚¹ã‚¯ã‚’è¨ˆç®—
    daily_risks = []
    
    if not data_sorted:
        return pd.DataFrame()  # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ç©ºã®DataFrameã‚’è¿”ã™
    
    # æœ€æ–°ã¨æœ€å¤ã®æ—¥ä»˜
    latest_date = max(ts.date() for _, ts in data_sorted)
    earliest_date = min(ts.date() for _, ts in data_sorted)
    
    # è¡¨ç¤ºã™ã‚‹æ—¥ä»˜ç¯„å›²
    date_range = [latest_date - pd.Timedelta(days=i) for i in range(days_to_show)]
    date_range = [d for d in date_range if d >= earliest_date]
    
    for target_date in sorted(date_range):
        # ãã®æ—¥ã®çµ‚ã‚ã‚Šï¼ˆæ¬¡ã®æ—¥ã®0æ™‚ï¼‰
        end_datetime = datetime.combine(target_date + pd.Timedelta(days=1), datetime.min.time())
        
        # éå»10æ—¥é–“ï¼ˆ240æ™‚é–“ï¼‰ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
        window_start = end_datetime - pd.Timedelta(hours=240)
        
        # ã“ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å†…ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        risk_window = [(temp, humidity) for (temp, humidity), ts in data_sorted 
                      if window_start <= ts < end_datetime]
        
        # ãƒªã‚¹ã‚¯æ™‚é–“ã‚’è¨ˆç®—
        risk_hours = sum(
            1 for temp, humidity in risk_window
            if 15 <= float(temp) <= 25 and float(humidity) >= 94
        )
        
        # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã¨ã‚«ãƒ©ãƒ¼ã‚’æ±ºå®š
        if risk_hours == 0:
            risk_level, color = "æ¥µä½", "gray"
        elif 0 < risk_hours <= 10:
            risk_level, color = "ä½", "blue"
        elif 10 < risk_hours <= 20:
            risk_level, color = "ä¸­", "green"
        elif 20 < risk_hours <= 39:
            risk_level, color = "é«˜", "orange"
        else:
            risk_level, color = "æ¥µé«˜", "red"
        
        daily_risks.append({
            'date': target_date,
            'risk_hours': risk_hours,
            'risk_level': risk_level,
            'color': color,
            'window_data_count': len(risk_window)
        })
    
    return pd.DataFrame(daily_risks)

# ã‚¹ãƒ”ãƒ¼ãƒ‰ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®ã¿ã‚’æ®‹ã—ã¦ä»–ã®å¯è¦–åŒ–é–¢æ•°ã‚’å‰Šé™¤
def plot_speedometer(percentage, color, risk_level, risk_hours):
    """
    è»Šã®ã‚¹ãƒ”ãƒ¼ãƒ‰ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®ã‚ˆã†ãªåŠå††å‹ã®ã‚²ãƒ¼ã‚¸ã§ãƒªã‚¹ã‚¯ã‚’è¡¨ç¤º
    """
    fig, ax = plt.subplots(figsize=(8, 4.5))
    
    fig.patch.set_facecolor('white')
    ax.set_facecolor('white')
    
    # èƒŒæ™¯ã®åŠå††å¼§ï¼ˆè–„ã„ã‚°ãƒ¬ãƒ¼ï¼‰
    theta = np.linspace(180, 0, 100) * np.pi / 180.0
    r = 0.8
    x = r * np.cos(theta)
    y = r * np.sin(theta)
    
    # èƒŒæ™¯ã®å¼§ï¼ˆã‚°ãƒ¬ãƒ¼ï¼‰
    ax.plot(x, y, color='lightgray', linewidth=20, solid_capstyle='round')
    
    # ãƒªã‚¹ã‚¯ã«å¿œã˜ãŸå¼§ã®æç”»
    end_angle = 180 - (percentage * 180)
    theta_risk = np.linspace(180, end_angle, 100) * np.pi / 180.0
    x_risk = r * np.cos(theta_risk)
    y_risk = r * np.sin(theta_risk)
    ax.plot(x_risk, y_risk, color=color, linewidth=20, solid_capstyle='round')
    
    # é‡ã®æç”»
    needle_angle = (180 - (percentage * 180)) * np.pi / 180.0
    needle_length = 0.9
    ax.plot([0, needle_length * np.cos(needle_angle)], 
            [0, needle_length * np.sin(needle_angle)], 
            color='black', linewidth=2)
    
    # é‡ã®ä¸­å¿ƒç‚¹
    circle = plt.Circle((0, 0), 0.05, color='darkgray')
    ax.add_patch(circle)
    
    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã‚’è£…é£¾ãƒœãƒƒã‚¯ã‚¹ã§è¡¨ç¤º
    text_box_props = dict(
        boxstyle='round,pad=0.5',
        facecolor=color,
        alpha=0.8,
        edgecolor='none'
    )
    
    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ - ç™½ã„æ–‡å­—ã§ç›®ç«‹ãŸã›ã‚‹
    ax.text(0, -0.4, f"ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«: {risk_level}", ha='center', va='center', 
            fontsize=16, fontweight='bold', color='white',
            bbox=text_box_props)
    
    # ãƒªã‚¹ã‚¯æ™‚é–“ã®ãƒ†ã‚­ã‚¹ãƒˆ
    ax.text(0, -0.6, f"{risk_hours}æ™‚é–“", ha='center', va='center', 
            fontsize=18, color='#303030')
    
    # ç›®ç››ã‚Šè¡¨ç¤ºï¼ˆãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ãƒ©ãƒ™ãƒ«ï¼‰
    # å„ãƒ©ãƒ™ãƒ«ã‚’å¯¾å¿œã™ã‚‹ãƒªã‚¹ã‚¯ç¯„å›²ã®ä¸­å¤®ã«é…ç½®
    # æ¥µä½=0æ™‚é–“, ä½=0-10ã®ä¸­é–“(5æ™‚é–“), ä¸­=10-20ã®ä¸­é–“(15æ™‚é–“), é«˜=30æ™‚é–“, æ¥µé«˜=40+æ™‚é–“
    labels = ["æ¥µä½", "ä½", "ä¸­", "é«˜", "æ¥µé«˜"]
    label_hours = [0, 5, 15, 30, 40]  # å„ãƒ©ãƒ™ãƒ«ã®æ™‚é–“ä½ç½®
    label_angles = [(180 - (h / 40) * 180) * np.pi / 180.0 for h in label_hours]
    for label, angle in zip(labels, label_angles):
        x = 1.1 * np.cos(angle)
        y = 1.1 * np.sin(angle)
        ax.text(x, y, label, ha='center', va='center', fontsize=18)
    
    # ã‚¹ã‚±ãƒ¼ãƒ«è¡¨ç¤ºï¼ˆæ™‚é–“æ•°ï¼‰- 0, 10, 20, 40+ã®ä½ç½®ã«è¡¨ç¤º
    scales = ["0", "10", "20", "", "40+"]
    scale_angles = np.linspace(180, 0, 5) * np.pi / 180.0  # å‡ç­‰é…ç½®
    for scale, angle in zip(scales, scale_angles):
        x = 0.81 * np.cos(angle)
        y = 0.81 * np.sin(angle)
        ax.text(x, y, scale, ha='center', va='center', fontsize=16, color='black')
    
    # ã‚°ãƒ©ãƒ•ã®è¨­å®š
    ax.set_xlim(-1.2, 1.2)
    ax.set_ylim(-0.8, 1.2)
    ax.set_aspect('equal')
    ax.axis('off')
    
    return fig

# ç°¡ç•¥åŒ–ã•ã‚ŒãŸãƒ¡ã‚¤ãƒ³å¯è¦–åŒ–é–¢æ•°ï¼ˆã‚¹ãƒ”ãƒ¼ãƒ‰ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®ã¿ï¼‰
def display_risk_visualization(risk_level, risk_hours):
    """
    ãƒªã‚¹ã‚¯è¡¨ç¤ºé–¢æ•°ï¼ˆã‚¹ãƒ”ãƒ¼ãƒ‰ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®ã¿å¯¾å¿œï¼‰
    """
    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã«å¯¾å¿œã™ã‚‹è‰²ã‚’æ›´æ–°
    colors = {
        "æ¥µä½": "#0000cc",  # é’
        "ä½": "#0000cc",    # é’
        "ä¸­": "#00cc00",    # ç·‘
        "é«˜": "#ff8000",    # ã‚ªãƒ¬ãƒ³ã‚¸
        "æ¥µé«˜": "#cc0000",  # èµ¤
        "ãƒ‡ãƒ¼ã‚¿ãªã—": "#808080"  # ã‚°ãƒ¬ãƒ¼
    }
    color = colors.get(risk_level, "#808080")
    
    # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸è¨ˆç®—ï¼ˆ40æ™‚é–“ã‚’æœ€å¤§å€¤ã¨ã—ã¦ï¼‰
    percentage = min(risk_hours / 40, 1)
    
    # ã‚¹ãƒ”ãƒ¼ãƒ‰ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’è¡¨ç¤º
    return plot_speedometer(percentage, color, risk_level, risk_hours)

def detect_device_type(file_path):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚«ãƒ©ãƒ åã‹ã‚‰ãƒ‡ãƒã‚¤ã‚¹ã‚¿ã‚¤ãƒ—ã‚’æ¨æ¸¬ã™ã‚‹é–¢æ•°
    ãƒ•ã‚¡ã‚¤ãƒ«åã«ã¯ä¾å­˜ã—ãªã„ï¼ˆã‚«ãƒ©ãƒ åã®ã¿ã§åˆ¤å®šï¼‰
    """
    header = None

    # UTF-8-sigï¼ˆBOMä»˜ãï¼‰ã§ã¾ãšè©¦ã™
    try:
        with open(file_path, 'rb') as f:
            raw = f.read(3)
        if raw == b'\xef\xbb\xbf':  # UTF-8 BOM
            with open(file_path, 'r', encoding='utf-8-sig') as f:
                header = f.readline()
            # KNå½¢å¼ï¼šæ¸©åº¦ã‚»ãƒ³ã‚µï¼‘ç­‰ã®å…¨è§’æ•°å­—ã‚’å«ã‚€
            if 'æ¸©åº¦ã‚»ãƒ³ã‚µï¼‘' in header or 'æ¸©åº¦ã‚»ãƒ³ã‚µï¼’' in header:
                return 'KN'
            # HNå½¢å¼ï¼šæ¸©åº¦(â„ƒ)ã¨ç›¸å¯¾æ¹¿åº¦(ï¼…)ãŒã‚ã‚‹
            if 'æ¸©åº¦(â„ƒ)' in header and 'ç›¸å¯¾æ¹¿åº¦(ï¼…)' in header:
                return 'HN'
    except Exception:
        pass

    # UTF-8ã§è©¦ã™ï¼ˆSwitchBotã‚·ãƒªãƒ¼ã‚ºï¼‰
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            header = f.readline()
        # SBå½¢å¼ï¼šSwitchBotç³»ï¼ˆæ­£å¸¸ã€ã‚¿ã‚¤ãƒå«ã‚€ï¼‰
        if any(pattern in header for pattern in ['Timestamp', 'Timamp', 'Temperature', 'Temperatre']):
            return 'SB'
    except UnicodeDecodeError:
        pass

    # Shift-JISã§è©¦ã™ï¼ˆæ—¥æœ¬èªã‚»ãƒ³ã‚µãƒ¼ï¼‰
    try:
        with open(file_path, 'r', encoding='shift-jis') as f:
            header = f.readline()

        # HZå½¢å¼ï¼šã¯ã‹ã‚‹è”µ
        if 'æ—¥ä»˜' in header and 'æ¸©åº¦' in header and 'æ¹¿åº¦' in header:
            return 'HZ'
        # PFå½¢å¼ï¼šãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ³ãƒ€ãƒ¼æ—§å‹
        if 'å¹´æœˆæ—¥' in header and 'æ°—æ¸©' in header:
            return 'PF'
        # OTå½¢å¼ï¼šãŠã‚“ã©ã¨ã‚Š
        if 'æ—¥ä»˜' in header and 'å®¤æ¸©' in header:
            return 'OT'
        # PF2å½¢å¼ï¼šãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ³ãƒ€ãƒ¼æ–°å‹
        if 'PF æ¸¬å®š' in header or ('æ—¥ä»˜' in header and 'æ™‚åˆ»' in header and 'æ¹¿åº¦' in header):
            return 'PF2'

    except UnicodeDecodeError:
        pass

    # æ¨æ¸¬ã§ããªã„å ´åˆã¯SBã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«
    return 'SB'

# æ£’ã‚°ãƒ©ãƒ•æç”»é–¢æ•°
def plot_risk_bar_chart(risk_df):
    """éå»ã®æ—¥åˆ¥ãƒªã‚¹ã‚¯ã‚’æ£’ã‚°ãƒ©ãƒ•ã§è¡¨ç¤ºã™ã‚‹é–¢æ•°ï¼ˆã‚¹ãƒãƒ›å¯¾å¿œç‰ˆã€æ—¥ä»˜ã‚’ä¸Šéƒ¨ã«é…ç½®ï¼‰"""
    # ã‚¹ãƒãƒ›ã«é©ã—ãŸã‚µã‚¤ã‚ºæ¯”ç‡
    fig, axes = plt.subplots(2, 1, figsize=(8, 6), gridspec_kw={'height_ratios': [4, 1]})
    ax = axes[0]  # ãƒ¡ã‚¤ãƒ³ã®æ£’ã‚°ãƒ©ãƒ•ç”¨
    ax_legend = axes[1]  # å‡¡ä¾‹ç”¨
    
    # æ—¥ä»˜ã‚’å¤ã„é †ã«ã‚½ãƒ¼ãƒˆ
    risk_df = risk_df.sort_values('date')
    
    # æ—¥ä»˜ã‚’æ–‡å­—åˆ—ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›
    date_labels = [d.strftime('%m/%d') for d in risk_df['date']]
    
    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã«å¯¾å¿œã™ã‚‹è‰²ã‚’å®šç¾©
    risk_colors = {
        "æ¥µä½": "#0000cc",  # é’
        "ä½": "#0000cc",    # é’
        "ä¸­": "#00cc00",    # ç·‘
        "é«˜": "#ff8000",    # ã‚ªãƒ¬ãƒ³ã‚¸
        "æ¥µé«˜": "#cc0000"   # èµ¤
    }
    
    # ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãè‰²ã®ãƒªã‚¹ãƒˆä½œæˆ
    bar_colors = [risk_colors[level] for level in risk_df['risk_level']]
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ã®Xè»¸ä½ç½®ã‚’ä½œæˆ
    x_positions = np.arange(len(risk_df))
    
    # æ£’ã‚°ãƒ©ãƒ•ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    bars = ax.bar(
        x_positions,
        risk_df['risk_hours'],
        color=bar_colors,
        width=0.7
    )
    
    # Xè»¸ã®ãƒ†ã‚£ãƒƒã‚¯ã¨ãƒ©ãƒ™ãƒ«ã‚’éè¡¨ç¤ºã«ã™ã‚‹
    ax.set_xticks([])
    ax.set_xticklabels([])
    
    # Yè»¸ã®è¨­å®š
    ax.set_ylabel('æ¡ä»¶ã‚’æº€ãŸã™æ™‚é–“æ•°', fontsize=16)
    
    # Yè»¸ã®ä¸Šé™ã‚’å›ºå®šã—ã¦ã€æ—¥ä»˜è¡¨ç¤ºç”¨ã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç¢ºä¿
    # åŸºæœ¬çš„ã«40æ™‚é–“ã‚’ä¸Šé™ã¨ã—ã€ãã‚Œã‚ˆã‚Šå¤§ãã„å€¤ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã«å°‘ã—ä½™è£•ã‚’æŒãŸã›ã‚‹
    max_data = risk_df['risk_hours'].max()

    # æ—¥ä»˜ãƒ©ãƒ™ãƒ«ã®ä½ç½®ã‚’å…ˆã«è¨ˆç®—ï¼ˆmax_data + 8ï¼‰ã—ã€ãã‚Œã‚ˆã‚Šä¸Šã«ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç¢ºä¿
    date_label_y = max(43, max_data + 8)
    y_limit = date_label_y + 12  # æ—¥ä»˜ãƒ©ãƒ™ãƒ«ã‚ˆã‚Šä¸Šã«ä½™è£•ã‚’æŒãŸã›ã‚‹
    ax.set_ylim(0, y_limit)
    
    # æœ€åˆã¨æœ€å¾Œã®æ—¥ä»˜ã‚’å–å¾—ã—ã¦æœŸé–“ã‚’ã‚¿ã‚¤ãƒˆãƒ«ã«è¡¨ç¤º
    first_date = date_labels[0]
    last_date = date_labels[-1]
    ax.set_title(f'éå»10æ—¥é–“ã®ç°è‰²ã‹ã³ç—…ãƒªã‚¹ã‚¯æ¨ç§»({first_date}ï½{last_date})', fontsize=18)
    
    # å„æ£’ã®ä¸Šã«æ™‚é–“æ•°ã‚’è¡¨ç¤º
    for i, (bar, hours) in enumerate(zip(bars, risk_df['risk_hours'])):
        height = bar.get_height()
        # æ™‚é–“æ•°ã‚’æ£’ã®ä¸Šã«è¡¨ç¤º
        ax.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{hours}æ™‚é–“',
                ha='center', va='bottom', fontsize=14, fontweight='bold')
    
    # æ—¥ä»˜ã‚’æ™‚é–“ãƒ©ãƒ™ãƒ«ã®ä¸Šã«è¡¨ç¤ºï¼ˆé‡ãªã‚Šã‚’é¿ã‘ã‚‹ï¼‰
    # date_label_y ã¯ä¸Šã§è¨ˆç®—æ¸ˆã¿
    for i, (x, date) in enumerate(zip(x_positions, date_labels)):
        # ã™ã¹ã¦ã®æ—¥ä»˜ã‚’è¡¨ç¤ºã™ã‚‹ã‹ã€å¶æ•°ç•ªç›®ã¨æœ€å¾Œã®æ—¥ä»˜ã®ã¿è¡¨ç¤ºã™ã‚‹ã‹ã‚’é¸æŠå¯èƒ½
        if i % 2 == 0 or i == len(date_labels) - 1:  # å¶æ•°ã¾ãŸã¯æœ€å¾Œã®ã¿è¡¨ç¤º
            ax.text(x, date_label_y, date, 
                    ha='center', va='bottom', fontsize=14)
    
    # ã‚°ãƒªãƒƒãƒ‰ç·šã‚’è¿½åŠ ã—ã¦èª­ã¿ã‚„ã™ãã™ã‚‹
    ax.yaxis.grid(True, linestyle='--', alpha=0.7)
    
    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã®å‡¡ä¾‹ã‚’ã‚¹ãƒãƒ›ã«æœ€é©åŒ–
    ax_legend.axis('off')  # è»¸ã‚’éè¡¨ç¤º
    
    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åŒºåˆ†ã‚’å®šç¾©
    risk_levels = ["æ¥µä½", "ä½", "ä¸­", "é«˜", "æ¥µé«˜"]
    risk_colors_list = [risk_colors["æ¥µä½"], risk_colors["ä½"], risk_colors["ä¸­"], 
                         risk_colors["é«˜"], risk_colors["æ¥µé«˜"]]
    
    # å‡¡ä¾‹ã‚’æ¨ªã«ä¸¦ã¹ã¦è¡¨ç¤ºï¼ˆã‚¹ãƒãƒ›ã«æœ€é©åŒ–ï¼‰
    
    box_width = 0.15
    gap = 0.05
    total_width = (box_width + gap) * len(risk_levels) - gap
    start_x = (1 - total_width) / 2
    
    for i, (level, color) in enumerate(zip(risk_levels, risk_colors_list)):
        x = start_x + i * (box_width + gap)
        # è‰²ä»˜ãã®ãƒœãƒƒã‚¯ã‚¹ã‚’æç”»
        rect = patches.Rectangle((x, 0.4), box_width, 0.4, facecolor=color)
        ax_legend.add_patch(rect)
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
        ax_legend.text(x + box_width/2, 0.15, level, ha='center', va='center', fontsize=16)
    
    # å‡¡ä¾‹ã®ã‚¿ã‚¤ãƒˆãƒ«
    ax_legend.text(0.5, 1.0, "ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åŒºåˆ†", ha='center', va='center', fontsize=16, fontweight='bold')
    
    plt.tight_layout()
    plt.subplots_adjust(hspace=0.1)  # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆé–“ã®éš™é–“ã‚’èª¿æ•´
    return fig

def plot_risk_heatmap(risk_df):
    """ãƒªã‚¹ã‚¯ã‚’ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å½¢å¼ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§è¡¨ç¤ºã™ã‚‹é–¢æ•°ï¼ˆã‚¹ãƒãƒ›å¯¾å¿œç‰ˆï¼‰"""
    # ã‚¹ãƒãƒ›å‘ã‘ã«ã‚µã‚¤ã‚ºã¨ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’èª¿æ•´
    fig, axes = plt.subplots(2, 1, figsize=(8, 1.8), gridspec_kw={'height_ratios': [1, 0.5]})
    ax = axes[0]  # ãƒ¡ã‚¤ãƒ³ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨
    ax_legend = axes[1]  # å‡¡ä¾‹ç”¨
    
    # æ—¥ä»˜ã‚’å¤ã„é †ã«ã‚½ãƒ¼ãƒˆã—ã€æœˆ-æ—¥å½¢å¼ã«å¤‰æ›
    risk_df = risk_df.sort_values('date')
    date_labels = [d.strftime('%m/%d') for d in risk_df['date']]
    
    # ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã®è¨­å®šï¼ˆãƒªã‚¹ã‚¯åŒºåˆ†ã«å¯¾å¿œã—ãŸé›¢æ•£çš„ãªè‰²ï¼‰
    from matplotlib.colors import ListedColormap, BoundaryNorm
    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã«å¯¾å¿œã™ã‚‹è‰²
    colors = [
        '#0000cc',  # æ¥µä½ï¼ˆ0æ™‚é–“ï¼‰: é’
        '#0000cc',  # ä½ï¼ˆ1-10æ™‚é–“ï¼‰: é’
        '#00cc00',  # ä¸­ï¼ˆ11-20æ™‚é–“ï¼‰: ç·‘
        '#ff8000',  # é«˜ï¼ˆ21-39æ™‚é–“ï¼‰: ã‚ªãƒ¬ãƒ³ã‚¸
        '#cc0000',  # æ¥µé«˜ï¼ˆ40+æ™‚é–“ï¼‰: èµ¤
    ]
    risk_cmap = ListedColormap(colors)
    # ãƒªã‚¹ã‚¯åŒºåˆ†ã®å¢ƒç•Œå€¤
    boundaries = [0, 1, 11, 21, 40, 100]
    norm = BoundaryNorm(boundaries, risk_cmap.N)
    
    # ãƒªã‚¹ã‚¯æ™‚é–“æ•°ã‚’2Dé…åˆ—ã«å¤‰æ›
    risk_matrix = risk_df['risk_hours'].values.reshape(1, -1)
    
    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®æç”»
    ax.pcolormesh(risk_matrix, cmap=risk_cmap, norm=norm, edgecolors='white', linewidth=1)
    
    # Yè»¸ãƒ©ãƒ™ãƒ«ã®è¨­å®šï¼ˆç©ºã«ã™ã‚‹ï¼‰
    ax.set_yticks([])
    
    # Xè»¸ã®è¨­å®š
    total_days = len(date_labels)
    xtick_positions = np.arange(total_days) + 0.5
    
    # æœ€åˆã¨æœ€å¾Œã®æ—¥ä»˜ã®ã¿ãƒ©ãƒ™ãƒ«è¡¨ç¤º
    ax.set_xticks([xtick_positions[0], xtick_positions[-1]])
    ax.set_xticklabels([date_labels[0], date_labels[-1]], fontsize=12, fontweight='bold')
    
    # æ—¥ä»˜ã®åŒºåˆ‡ã‚Šç·šï¼ˆè–„ãï¼‰
    for x in xtick_positions:
        ax.axvline(x, color='lightgray', linestyle='-', linewidth=0.3, alpha=0.2)
    
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    ax.set_title(f"éå»30æ—¥é–“ã®ç°è‰²ã‹ã³ç—…ãƒªã‚¹ã‚¯æ¨ç§» ({date_labels[0]}ï½{date_labels[-1]})", fontsize=18)
    
    # å‡¡ä¾‹ã‚’æç”»ã™ã‚‹ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã®è¨­å®š
    ax_legend.axis('off')

    plt.tight_layout()
    plt.subplots_adjust(hspace=0.05)
    return fig

def main():
    st.set_page_config(page_title="ğŸ“ ã‚¤ãƒã‚´ç°è‰²ã‹ã³ç—…ãƒªã‚¹ã‚¯åˆ¤å®šãƒ„ãƒ¼ãƒ«", layout="wide")
    st.title("ğŸ“ ã‚¤ãƒã‚´ç°è‰²ã‹ã³ç—…ãƒªã‚¹ã‚¯åˆ¤å®šãƒ„ãƒ¼ãƒ«")
    st.header("ğŸ‘‡CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\nã€€â€»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯çµ‚äº†æ™‚ã«è‡ªå‹•çš„ã«å‰Šé™¤ã•ã‚Œã¾ã™ã€‚")

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼ˆã‚»ãƒ³ã‚µãƒ¼ã‚¿ã‚¤ãƒ—ã¯è‡ªå‹•æ¤œå‡ºã®ã¿ï¼‰
    uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚", type=["csv", "xlsx", "xls"])

    if uploaded_file is not None:
        # ã‚»ãƒ³ã‚µãƒ¼ã‚¿ã‚¤ãƒ—ã¯è‡ªå‹•æ¤œå‡ºï¼ˆNoneã‚’æ¸¡ã™ï¼‰
        selected_device = None
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã§å‡¦ç†çŠ¶æ³ã‚’è¡¨ç¤º
        with st.spinner('ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...'):
            # æ‹¡å¼µç‰ˆé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ï¼ˆ30æ—¥åˆ†ã®ã¿ï¼‰
            temperature, relative_humidity, timestamps = read_temperature_and_humidity_data(
                uploaded_file, device_type=selected_device, days_to_keep=30
            )

        if temperature is not None and relative_humidity is not None:
            # ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡¨ç¤º
            
            # æ¸©åº¦ãƒ»æ¹¿åº¦ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚¹ãƒˆåŒ–
            temp_humidity_data = list(zip(temperature, relative_humidity))

            # ç¾åœ¨ã®ãƒªã‚¹ã‚¯è¨ˆç®—ï¼ˆæœ€æ–°ã®10æ—¥é–“ï¼‰
            current_risk_level, current_risk_hours, current_color = check_gray_mold_risk(temp_humidity_data, timestamps)
            
            # æ™‚ç³»åˆ—ãƒªã‚¹ã‚¯è¨ˆç®—
            time_series_risk_df = calculate_time_series_risk(temp_humidity_data, timestamps, days_to_show=28)

            # 1. ãƒ¡ã‚¤ãƒ³ã®ç¾åœ¨ãƒªã‚¹ã‚¯è¡¨ç¤ºï¼ˆã‚¹ãƒ”ãƒ¼ãƒ‰ãƒ¡ãƒ¼ã‚¿ãƒ¼ï¼‰
            # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«è¡¨ç¤º
            st.markdown(f"<h2 style='color: {current_color};'>ç°è‰²ã‹ã³ç—…ã®ç™ºç—…ãƒªã‚¹ã‚¯: {current_risk_level}</h2>", unsafe_allow_html=True)
            st.markdown(f"<p style='font-size:18px; font-weight:bold;'>éå»10æ—¥é–“ã§æ¡ä»¶ã‚’æº€ãŸã™æ™‚é–“æ•°: {current_risk_hours}æ™‚é–“</p>", unsafe_allow_html=True)

            # æ¨å¥¨å¯¾ç­–è¡¨ç¤º
            recommendations = {
                "æ¥µä½": "æœ¬ç—…ã®ç™ºç”Ÿãƒªã‚¹ã‚¯ã¯æ¥µã‚ã¦ä½ã„ã®ã§ã€ä»–ä½œæ¥­ï¼ˆåç©«ç­‰ï¼‰ã«é›†ä¸­ã—ã¦ãã ã•ã„ã€‚",
                "ä½": "æœ¬ç—…ã®ç™ºç”Ÿãƒªã‚¹ã‚¯ã¯ä½ã„ã§ã™ãŒã€è€•ç¨®çš„é˜²é™¤ã‚’å®Ÿæ–½ã™ã‚‹ã¨ãªãŠè‰¯ã„ã§ã—ã‚‡ã†ã€‚",
                "ä¸­": "äºˆé˜²çš„ãªè€•ç¨®çš„é˜²é™¤åŠã³è–¬å‰¤é˜²é™¤ã®å®Ÿæ–½ãŒãŠå‹§ã‚ã§ã™ã€‚",
                "é«˜": "è€•ç¨®çš„é˜²é™¤ã¨è–¬å‰¤é˜²é™¤ã®å®Ÿæ–½ãŒå¿…è¦ã§ã™ã€‚",
                "æ¥µé«˜": "ä»Šã™ãã«è€•ç¨®çš„é˜²é™¤ã¨è–¬å‰¤é˜²é™¤ã®å®Ÿæ–½ãŒå¿…è¦ã§ã™ã€‚",
                "ãƒ‡ãƒ¼ã‚¿ãªã—": "ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            }
            st.markdown(f"<p style='font-size:16px;'><span style='font-weight:bold;'>æ¨å¥¨å¯¾ç­–:</span> {recommendations[current_risk_level]}</p>", unsafe_allow_html=True)
            # ã‚¹ãƒ”ãƒ¼ãƒ‰ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’è¡¨ç¤º
            risk_viz_fig = display_risk_visualization(current_risk_level, current_risk_hours)
            st.pyplot(risk_viz_fig)
            
            # åŒºåˆ‡ã‚Šç·šã‚’è¡¨ç¤º
            st.markdown("---")
            
            # 2. æ™‚ç³»åˆ—ãƒªã‚¹ã‚¯ã®æ£’ã‚°ãƒ©ãƒ•è¡¨ç¤º
            if not time_series_risk_df.empty:
                
                # æ£’ã‚°ãƒ©ãƒ•ç”¨ã«ç›´è¿‘10æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                recent_10_days = time_series_risk_df.sort_values('date', ascending=False).head(10).sort_values('date')
                bar_fig = plot_risk_bar_chart(recent_10_days)
                st.pyplot(bar_fig)
                
                # åŒºåˆ‡ã‚Šç·šã‚’è¡¨ç¤º
                st.markdown("---")
                
                # 3. æ™‚ç³»åˆ—ãƒªã‚¹ã‚¯ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—è¡¨ç¤ºï¼ˆ30æ—¥é–“ï¼‰
                heat_fig = plot_risk_heatmap(time_series_risk_df)
                st.pyplot(heat_fig)
                
                # è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤º
                with st.expander("è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º"):
                    display_df = time_series_risk_df[['date', 'risk_hours', 'risk_level']].copy()
                    
                    # .dt ã‚¢ã‚¯ã‚»ã‚µãƒ¼ã‚’ä½¿ã†å‰ã«å‹ãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ 
                    if pd.api.types.is_datetime64_any_dtype(display_df['date']):
                        display_df['date'] = display_df['date'].dt.strftime('%Y-%m-%d')
                    else:
                        display_df['date'] = display_df['date'].astype(str)
                    
                    display_df.columns = ['æ—¥ä»˜', 'ãƒªã‚¹ã‚¯æ™‚é–“æ•°', 'ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«']
                    st.dataframe(display_df)
            else:
                st.warning("è¡¨ç¤ºå¯èƒ½ãªæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚ˆã‚Šé•·æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

    # ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ãƒˆè¡¨ç¤º
    st.markdown("---")
    st.markdown(
        "<p style='text-align: center; color: gray; font-size: 12px;'>"
        "&copy; å¤§åˆ†çœŒè¾²æ—æ°´ç”£ç ”ç©¶æŒ‡å°ã‚»ãƒ³ã‚¿ãƒ¼è¾²æ¥­ç ”ç©¶éƒ¨"
        "</p>",
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()